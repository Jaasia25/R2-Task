{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612f8382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Misclassified: 49\n",
      "{'image': 'IMG_2446_jpeg_jpg.rf.06ee05e92df8e3c33073147d8f595211.jpg', 'gt': ['shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark'], 'pred': ['fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'shark', 'shark']}\n",
      "{'image': 'IMG_2395_jpeg_jpg.rf.9f1503ad3b7a7c7938daed057cc4e9bc.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2380_jpeg_jpg.rf.a23809682eb1466c1136ca0f55de8fb5.jpg', 'gt': ['fish'], 'pred': ['fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2347_jpeg_jpg.rf.7c71ac4b9301eb358cd4a832844dedcb.jpg', 'gt': ['penguin', 'penguin'], 'pred': ['penguin']}\n",
      "{'image': 'IMG_2379_jpeg_jpg.rf.7dc3160c937072d26d4624c6c48e904d.jpg', 'gt': ['fish'], 'pred': ['fish', 'shark']}\n",
      "{'image': 'IMG_8582_MOV-5_jpg.rf.9d7a26fbf145ce39ab0831b4e6bc1f1e.jpg', 'gt': ['stingray', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish']}\n",
      "{'image': 'IMG_3144_jpeg_jpg.rf.f29a36360174dc83ecef93275ed8f02e.jpg', 'gt': ['puffin', 'puffin'], 'pred': ['puffin', 'puffin', 'puffin']}\n",
      "{'image': 'IMG_2468_jpeg_jpg.rf.c933cc14c99b11a90413a1490d4556db.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_8420_jpg.rf.31f1d5f1440e48ccf1dee988b565911b.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark'], 'pred': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2448_jpeg_jpg.rf.28ce79dab47ad525751d5407be09bc3d.jpg', 'gt': ['shark', 'fish', 'shark', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'shark', 'fish', 'jellyfish']}\n",
      "{'image': 'IMG_8452_jpg.rf.6bbff701ab93e29553b3a70137fd4e66.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg', 'gt': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin'], 'pred': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin']}\n",
      "{'image': 'IMG_3173_jpeg_jpg.rf.6f05acaa0b22d410a5df3ea3286e227d.jpg', 'gt': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin'], 'pred': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin']}\n",
      "{'image': 'IMG_8343_jpg.rf.2d88000497d74d72aedc118b125a0c07.jpg', 'gt': ['fish', 'fish'], 'pred': ['fish', 'fish', 'shark']}\n",
      "{'image': 'IMG_2526_jpeg_jpg.rf.003e1d1d41bcd204df731b85cea68781.jpg', 'gt': ['puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin'], 'pred': ['puffin', 'puffin', 'puffin', 'puffin']}\n",
      "{'image': 'IMG_2473_jpeg_jpg.rf.6284677f9c781b0cfeec54981a17d573.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_2582_jpeg_jpg.rf.14f175066ce74b470bf31fa0c7a096cd.jpg', 'gt': ['stingray', 'shark', 'stingray', 'fish', 'shark', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['shark', 'stingray', 'shark', 'fish', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish']}\n",
      "{'image': 'IMG_8497_MOV-0_jpg.rf.5c59bd1bf7d8fd7a20999d51a79a12c0.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_8590_MOV-5_jpg.rf.074e6d8acdd3fcad16d866c341b43769.jpg', 'gt': ['stingray'], 'pred': ['jellyfish', 'stingray']}\n",
      "{'image': 'IMG_8395_jpg.rf.3bebece033961c9f665571644a14261f.jpg', 'gt': ['shark', 'shark', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark'], 'pred': ['shark', 'shark', 'shark', 'shark', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2477_jpeg_jpg.rf.7b2692f142d53c16ad477065f1f8ae6d.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_8515_jpg.rf.98a9daca7c5a5bad9872bd7fb2d4f198.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_8582_MOV-0_jpg.rf.aa8304d7a5112d63c8841d96160d42cd.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'stingray'], 'pred': ['stingray', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_8404_jpg.rf.265b89e862a375f6b89f781ea60ed480.jpg', 'gt': ['stingray', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark'], 'pred': ['stingray', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2371_jpeg_jpg.rf.54505f60b6706da151c164188c305849.jpg', 'gt': ['fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'shark', 'fish', 'shark', 'shark', 'fish', 'shark']}\n",
      "{'image': 'IMG_2434_jpeg_jpg.rf.8b20d3270d4fbc497c64125273f46ecb.jpg', 'gt': ['shark', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2499_jpeg_jpg.rf.6cbab3719b9063388b5ab3ab826d7bd3.jpg', 'gt': ['shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_8490_jpg.rf.1836542cf054c6d303a2dd05d4194d7f.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_2289_jpeg_jpg.rf.fe2a7a149e7b11f2313f5a7b30386e85.jpg', 'gt': ['puffin'], 'pred': ['stingray', 'puffin']}\n",
      "{'image': 'IMG_8595_MOV-0_jpg.rf.312ab0b8b9fca18134aee88044f45a06.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_3136_jpeg_jpg.rf.0d8fef73d4cc5e1c35ce424444d9e44b.jpg', 'gt': ['puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin'], 'pred': ['puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin']}\n",
      "{'image': 'IMG_3175_jpeg_jpg.rf.686c7d36e049eea974a363e99bf0bee0.jpg', 'gt': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin'], 'pred': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin']}\n",
      "{'image': 'IMG_8497_MOV-5_jpg.rf.3deffb208d656b7845661c5e33dd1afb.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2470_jpeg_jpg.rf.75b359c8baa6866bfecf07a0e4e8c33d.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_2423_jpeg_jpg.rf.1c0901882e71d5ebd26f036f4e22da65.jpg', 'gt': ['fish', 'fish', 'shark', 'shark', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark', 'fish'], 'pred': ['shark', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark']}\n",
      "{'image': 'IMG_2632_jpeg_jpg.rf.f44037edca490b16cbf06427e28ea946.jpg', 'gt': ['stingray', 'fish', 'stingray', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['stingray', 'fish', 'fish', 'fish', 'stingray', 'fish', 'fish', 'shark', 'fish']}\n",
      "{'image': 'IMG_8513_MOV-0_jpg.rf.2a2f77e3f73630b60aaf6ad3ca4ed130.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'penguin', 'fish', 'fish']}\n",
      "{'image': 'IMG_2651_jpeg_jpg.rf.84b3930aa80b610cc97bf1c176763940.jpg', 'gt': ['stingray'], 'pred': ['stingray', 'starfish']}\n",
      "{'image': 'IMG_2465_jpeg_jpg.rf.7e699ec1d2e373d93dac32cd02db9438.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_3164_jpeg_jpg.rf.06637eee0b72df791aa729807ca45c4d.jpg', 'gt': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin'], 'pred': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin']}\n",
      "{'image': 'IMG_3134_jpeg_jpg.rf.50750ca778773042a3c46a1d3e480132.jpg', 'gt': ['puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin', 'puffin'], 'pred': ['puffin', 'puffin', 'puffin', 'puffin']}\n",
      "{'image': 'IMG_8497_MOV-3_jpg.rf.fd813e14681c8b41e709a500748ce46a.jpg', 'gt': ['fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_8396_jpg.rf.106a6ced5c649ea81f0de8ecaa4ff3b8.jpg', 'gt': ['shark', 'shark', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark'], 'pred': ['shark', 'shark', 'shark', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2496_jpeg_jpg.rf.3f91e7f18502074c89fa720a11926fab.jpg', 'gt': ['shark', 'shark', 'fish', 'stingray', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish'], 'pred': ['shark', 'shark', 'fish', 'shark', 'fish', 'fish', 'fish', 'stingray', 'fish', 'fish', 'fish', 'stingray']}\n",
      "{'image': 'IMG_2574_jpeg_jpg.rf.ca0c3ad32384309a61e92d9a8bef87b9.jpg', 'gt': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish'], 'pred': ['jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish', 'jellyfish']}\n",
      "{'image': 'IMG_2570_jpeg_jpg.rf.ed40900b657a5b23d92cb2d296ad2dbc.jpg', 'gt': ['shark', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark'], 'pred': ['shark', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2450_jpeg_jpg.rf.ff673921373de3bfc275863e3befeefe.jpg', 'gt': ['shark', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish'], 'pred': ['shark', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2630_jpeg_jpg.rf.310f0c986a72be46b80ce31c2d00e46d.jpg', 'gt': ['stingray', 'stingray', 'fish', 'fish', 'fish'], 'pred': ['stingray', 'fish', 'fish', 'fish', 'fish', 'fish']}\n",
      "{'image': 'IMG_2319_jpeg_jpg.rf.6e20bf97d17b74a8948aa48776c40454.jpg', 'gt': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin'], 'pred': ['penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin', 'penguin']}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIG\n",
    "# ---------------------------\n",
    "MODEL_PATH = \"models/fish_yolov8/weights/best.pt\"\n",
    "TEST_IMAGES = \"data/aquarium_pretrain/test/images\"\n",
    "TEST_LABELS = \"data/aquarium_pretrain/test/labels\"\n",
    "\n",
    "SAVE_MISCLASSIFIED = True\n",
    "\n",
    "OUT_PRED_DIR = \"misclassified_yolo\"              # predictions (RED)\n",
    "OUT_GT_DIR = \"misclassified_ground_truth\"        # actual labels (GREEN)\n",
    "\n",
    "CLASSES = ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n",
    "\n",
    "os.makedirs(OUT_PRED_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_GT_DIR, exist_ok=True)\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# ---------------------------\n",
    "# HELPER: Read YOLO GT labels\n",
    "# ---------------------------\n",
    "def read_yolo_label(label_path, img_w, img_h):\n",
    "    boxes = []\n",
    "    if not os.path.exists(label_path):\n",
    "        return boxes\n",
    "\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            cls = int(parts[0])\n",
    "            xc, yc, w, h = map(float, parts[1:])\n",
    "\n",
    "            # Convert normalized â†’ pixel xyxy\n",
    "            x1 = int((xc - w / 2) * img_w)\n",
    "            y1 = int((yc - h / 2) * img_h)\n",
    "            x2 = int((xc + w / 2) * img_w)\n",
    "            y2 = int((yc + h / 2) * img_h)\n",
    "\n",
    "            boxes.append((cls, x1, y1, x2, y2))\n",
    "\n",
    "    return boxes\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN LOOP\n",
    "# ---------------------------\n",
    "misclassified = []\n",
    "\n",
    "for img_name in os.listdir(TEST_IMAGES):\n",
    "    if not img_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(TEST_IMAGES, img_name)\n",
    "    label_path = os.path.join(\n",
    "        TEST_LABELS, img_name.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "    )\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img_h, img_w = img.shape[:2]\n",
    "\n",
    "    # --- Read ground truth ---\n",
    "    gt_boxes = read_yolo_label(label_path, img_w, img_h)\n",
    "    gt_classes = [b[0] for b in gt_boxes]\n",
    "\n",
    "    # --- Predict ---\n",
    "    results = model.predict(img_path, conf=0.25, verbose=False)[0]\n",
    "    pred_classes = [\n",
    "        int(box.cls[0]) for box in results.boxes\n",
    "    ] if results.boxes is not None else []\n",
    "\n",
    "    # ---------------------------\n",
    "    # If misclassified\n",
    "    # ---------------------------\n",
    "    if sorted(gt_classes) != sorted(pred_classes):\n",
    "        misclassified.append({\n",
    "            \"image\": img_name,\n",
    "            \"gt\": [CLASSES[c] for c in gt_classes],\n",
    "            \"pred\": [CLASSES[c] for c in pred_classes]\n",
    "        })\n",
    "\n",
    "        if SAVE_MISCLASSIFIED:\n",
    "\n",
    "            # COPY of original for prediction drawing\n",
    "            pred_img = img.copy()\n",
    "\n",
    "            # COPY of original for GT drawing\n",
    "            gt_img = img.copy()\n",
    "\n",
    "            # ---------------------------\n",
    "            # DRAW GROUND TRUTH (GREEN)\n",
    "            # ---------------------------\n",
    "            for cls, x1, y1, x2, y2 in gt_boxes:\n",
    "                cls_name = CLASSES[cls]\n",
    "\n",
    "                cv2.rectangle(gt_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(\n",
    "                    gt_img,\n",
    "                    f\"GT: {cls_name}\",\n",
    "                    (x1, max(y1 - 8, 5)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    (0, 255, 0),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "            # Save ground-truth only image\n",
    "            cv2.imwrite(os.path.join(OUT_GT_DIR, img_name), gt_img)\n",
    "\n",
    "            # ---------------------------\n",
    "            # DRAW PREDICTIONS (RED)\n",
    "            # ---------------------------\n",
    "            if results.boxes is not None:\n",
    "                for box in results.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cls_id = int(box.cls[0])\n",
    "                    cls_name = CLASSES[cls_id]\n",
    "\n",
    "                    cv2.rectangle(pred_img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                    cv2.putText(\n",
    "                        pred_img,\n",
    "                        f\"Pred: {cls_name}\",\n",
    "                        (x1, max(y1 - 8, 5)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6,\n",
    "                        (0, 0, 255),\n",
    "                        2\n",
    "                    )\n",
    "\n",
    "            # Save predicted result only\n",
    "            cv2.imwrite(os.path.join(OUT_PRED_DIR, img_name), pred_img)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# SUMMARY\n",
    "# ---------------------------\n",
    "print(\"\\nTotal Misclassified:\", len(misclassified))\n",
    "for m in misclassified:\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eebaab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.228 ðŸš€ Python-3.11.2 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4090, 24210MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 92 layers, 25,843,813 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 5135.4Â±2124.8 MB/s, size: 501.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/Jaasia/Fish_Detection/data/labels/valid_aug.cache... 595 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 595/595 2.2Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 12.5it/s 3.0s0.1s\n",
      "                   all        595       3206      0.816       0.65      0.735      0.457\n",
      "                  fish        238       1197      0.883      0.606      0.739      0.403\n",
      "             jellyfish         42        679      0.892      0.851      0.925      0.609\n",
      "               penguin         70        427      0.535      0.365      0.383      0.217\n",
      "                puffin         77        329      0.671       0.54      0.629      0.345\n",
      "                 shark        238        357      0.846      0.677      0.733      0.428\n",
      "              starfish         49         91      0.983      0.629      0.799      0.531\n",
      "              stingray         77        126      0.905      0.881      0.938      0.668\n",
      "Speed: 0.5ms preprocess, 3.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/workspace/chatbot/runs/detect/val7\u001b[0m\n",
      "mAP50: 0.7350456646644387\n",
      "mAP50-95: 0.4573047061354358\n",
      "Precision: 0.8164492804032184\n",
      "Recall: 0.6498850284419176\n",
      "\n",
      "Class-wise AP:\n",
      "[    0.40326     0.60905     0.21703      0.3448     0.42789     0.53091     0.66819]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"models/fish_yolov86/weights/best.pt\")\n",
    "\n",
    "# Run evaluation on your test set\n",
    "results = model.val(data=\"data/dataset.yaml\")   # or your dataset YAML\n",
    "\n",
    "# Print metrics\n",
    "print(\"mAP50:\", results.box.map50)\n",
    "print(\"mAP50-95:\", results.box.map)\n",
    "print(\"Precision:\", results.box.mp)\n",
    "print(\"Recall:\", results.box.mr)\n",
    "\n",
    "# Class-wise AP\n",
    "print(\"\\nClass-wise AP:\")\n",
    "print(results.box.maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858ca4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 169 layers, 25,860,373 parameters, 0 gradients, 79.1 GFLOPs\n",
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-3): 4 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-3): 4 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(576, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(288, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Detect(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(192, 7, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"models/fish_yolov86/weights/best.pt\")\n",
    "model.info()  # instead of model.summary()\n",
    "\n",
    "print(model.model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e62198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'shark' confidence score: 0.9030\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCategory \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m confidence score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# ------------------- FORWARD PASS WITH GRADIENTS -------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# triggers forward hook\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# ------------------- BACKWARD PASS -------------------\u001b[39;00m\n\u001b[32m     63\u001b[39m model.model.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/ultralytics/nn/tasks.py:137\u001b[39m, in \u001b[36mBaseModel.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss(x, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/ultralytics/nn/tasks.py:154\u001b[39m, in \u001b[36mBaseModel.predict\u001b[39m\u001b[34m(self, x, profile, visualize, augment, embed)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._predict_augment(x)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/ultralytics/nn/tasks.py:176\u001b[39m, in \u001b[36mBaseModel._predict_once\u001b[39m\u001b[34m(self, x, profile, visualize, embed)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    177\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/module.py:1881\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1880\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1881\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1883\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1884\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1885\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1886\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/module.py:1829\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1826\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1827\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1829\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1830\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1831\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1832\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1833\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1834\u001b[39m     ):\n\u001b[32m   1835\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:89\u001b[39m, in \u001b[36mConv.forward_fuse\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     81\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[32m     82\u001b[39m \n\u001b[32m     83\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m \u001b[33;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/Jaasia/Fish_Detection/fish/lib/python3.11/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "image_path = \"data/images/test/00000000_jpg.rf.5d9188ebfd1f9ae1b9989c8ffc6bd7c4.jpg\"\n",
    "category = \"shark\"\n",
    "classes = ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n",
    "model_path = \"models/fish_yolov86/weights/best.pt\"\n",
    "\n",
    "# ------------------- LOAD MODEL -------------------\n",
    "model = YOLO(model_path)\n",
    "model.eval()\n",
    "\n",
    "# ------------------- PREPROCESS IMAGE -------------------\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_resized = cv2.resize(img, (640, 640))\n",
    "    img_tensor = torch.tensor(img_resized).permute(2,0,1).unsqueeze(0).float() / 255.0\n",
    "    img_tensor.requires_grad = True\n",
    "    return img_tensor, img\n",
    "\n",
    "x, orig_img = preprocess_image(image_path)\n",
    "\n",
    "# ------------------- PICK CONV LAYER -------------------\n",
    "# YOLOv8 backbone first conv block\n",
    "target_layer = model.model.model[0]\n",
    "\n",
    "feature_maps = {}\n",
    "gradients = {}\n",
    "\n",
    "def forward_hook(module, input, output):\n",
    "    feature_maps['hooked'] = output\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    gradients['hooked'] = grad_out[0]\n",
    "\n",
    "target_layer.register_forward_hook(forward_hook)\n",
    "target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "# ------------------- GET CATEGORY CONFIDENCE -------------------\n",
    "# Use model.predict to get real detection scores\n",
    "dets = model.predict(image_path, verbose=False)[0]  # first image\n",
    "boxes = dets.boxes\n",
    "obj_scores = boxes.conf\n",
    "class_indices = boxes.cls\n",
    "class_idx = classes.index(category)\n",
    "\n",
    "mask = (class_indices == class_idx)\n",
    "if mask.sum() > 0:\n",
    "    score = (obj_scores[mask]).max().item()\n",
    "else:\n",
    "    score = 0.0\n",
    "\n",
    "print(f\"Category '{category}' confidence score: {score:.4f}\")\n",
    "\n",
    "# ------------------- FORWARD PASS WITH GRADIENTS -------------------\n",
    "outputs = model.model(x)  # triggers forward hook\n",
    "\n",
    "# ------------------- BACKWARD PASS -------------------\n",
    "model.model.zero_grad()\n",
    "scalar_score = torch.tensor(score, requires_grad=True)\n",
    "scalar_score.backward(retain_graph=True)  # triggers backward hook\n",
    "\n",
    "# ------------------- COMPUTE GRADCAM -------------------\n",
    "fmap = feature_maps['hooked'][0]  # [C,H,W]\n",
    "grad = gradients['hooked'][0]     # [C,H,W]\n",
    "\n",
    "weights = torch.mean(grad, dim=(1,2))\n",
    "gradcam_map = torch.zeros(fmap.shape[1:], dtype=torch.float32)\n",
    "for i in range(weights.shape[0]):\n",
    "    gradcam_map += weights[i] * fmap[i]\n",
    "\n",
    "gradcam_map = torch.relu(gradcam_map)\n",
    "gradcam_map -= gradcam_map.min()\n",
    "gradcam_map /= gradcam_map.max()\n",
    "gradcam_resized = cv2.resize(gradcam_map.detach().cpu().numpy(), (orig_img.shape[1], orig_img.shape[0]))\n",
    "\n",
    "# ------------------- OVERLAY HEATMAP -------------------\n",
    "def overlay_heatmap(img, heatmap, alpha=0.4):\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, alpha, heatmap, 1 - alpha, 0)\n",
    "    return superimposed_img\n",
    "\n",
    "output_img = overlay_heatmap(orig_img, gradcam_resized)\n",
    "cv2.imwrite(\"heatmap/yolov8_gradcam.jpg\", output_img)\n",
    "print(\"GradCAM heatmap saved as 'heatmap/yolov8_gradcam.jpg'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
